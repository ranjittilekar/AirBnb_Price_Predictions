{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dwu007/Desktop/Production/AirBnbPrediction\n"
     ]
    }
   ],
   "source": [
    "# Initate variable to create Root Path\n",
    "rootDirectory = os.path.abspath('..')\n",
    "rootDirectory = str(rootDirectory)\n",
    "print(rootDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Parameter\n",
    "os.chdir(rootDirectory)\n",
    "# from src import parameters\n",
    "# from src import program\n",
    "# from src.data import make_dataset\n",
    "# from src.features import build_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update parameter.py for inputs\n",
    "# Run program.py to perform data prep\n",
    "# Notebook call not working at the moment\n",
    "\n",
    "# program.fx_make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update parameter.py for inputs\n",
    "# Run program.py to perform data prep\n",
    "# Notebook call not working at the moment\n",
    "\n",
    "# program.fx_build_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update parameter.py for inputs\n",
    "# Run program.py to perform data prep\n",
    "# Notebook call not working at the moment\n",
    "\n",
    "# program.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>description_length</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>cancellation_policy_super_strict_30</th>\n",
       "      <th>cancellation_policy_super_strict_60</th>\n",
       "      <th>host_has_profile_pic_Blank</th>\n",
       "      <th>host_has_profile_pic_f</th>\n",
       "      <th>host_has_profile_pic_t</th>\n",
       "      <th>host_identity_verified_Blank</th>\n",
       "      <th>host_identity_verified_f</th>\n",
       "      <th>host_identity_verified_t</th>\n",
       "      <th>instant_bookable_f</th>\n",
       "      <th>instant_bookable_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>-1.780</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.766</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>1.834</td>\n",
       "      <td>1.342</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.753</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.094</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.342</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.767</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.668</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-1.296</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>-7.810</td>\n",
       "      <td>-2.213</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>0.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bathrooms  host_response_rate  number_of_reviews  \\\n",
       "0         0.147     -0.435               0.295             -0.576   \n",
       "1         1.766     -0.435               0.295             -0.021   \n",
       "2         1.094     -0.435               0.295              0.275   \n",
       "3         0.668     -0.435               0.295             -1.296   \n",
       "4        -0.525     -0.435               0.295             -0.241   \n",
       "\n",
       "   review_scores_rating  bedrooms   beds  amenities_count  description_length  \\\n",
       "0                 0.789    -0.189 -0.687           -1.079              -1.780   \n",
       "1                -0.214     1.834  1.342           -0.802               0.677   \n",
       "2                -0.357    -0.189  1.342            0.029               0.659   \n",
       "3                 0.216     0.994  0.500           -0.525              -0.937   \n",
       "4                -7.810    -2.213 -0.687           -0.802              -0.273   \n",
       "\n",
       "   latitude         ...          cancellation_policy_super_strict_30  \\\n",
       "0     0.731         ...                                            0   \n",
       "1     0.753         ...                                            0   \n",
       "2     0.767         ...                                            0   \n",
       "3    -0.218         ...                                            0   \n",
       "4     0.156         ...                                            0   \n",
       "\n",
       "   cancellation_policy_super_strict_60  host_has_profile_pic_Blank  \\\n",
       "0                                    0                           0   \n",
       "1                                    0                           0   \n",
       "2                                    0                           0   \n",
       "3                                    0                           0   \n",
       "4                                    0                           0   \n",
       "\n",
       "   host_has_profile_pic_f  host_has_profile_pic_t  \\\n",
       "0                       0                       1   \n",
       "1                       0                       1   \n",
       "2                       0                       1   \n",
       "3                       0                       1   \n",
       "4                       0                       1   \n",
       "\n",
       "   host_identity_verified_Blank  host_identity_verified_f  \\\n",
       "0                             0                         0   \n",
       "1                             0                         1   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "\n",
       "   host_identity_verified_t  instant_bookable_f  instant_bookable_t  \n",
       "0                         1                   1                   0  \n",
       "1                         0                   0                   1  \n",
       "2                         1                   0                   1  \n",
       "3                         1                   1                   0  \n",
       "4                         1                   0                   1  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv(rootDirectory+\"/data/processed/X_train.csv\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.010635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.129899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.976734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.620073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.744932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_price\n",
       "0   5.010635\n",
       "1   5.129899\n",
       "2   4.976734\n",
       "3   6.620073\n",
       "4   4.744932"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv(rootDirectory+\"/data/processed/y_train.csv\")\n",
    "y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>description_length</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>cancellation_policy_super_strict_30</th>\n",
       "      <th>cancellation_policy_super_strict_60</th>\n",
       "      <th>host_has_profile_pic_Blank</th>\n",
       "      <th>host_has_profile_pic_f</th>\n",
       "      <th>host_has_profile_pic_t</th>\n",
       "      <th>host_identity_verified_Blank</th>\n",
       "      <th>host_identity_verified_f</th>\n",
       "      <th>host_identity_verified_t</th>\n",
       "      <th>instant_bookable_f</th>\n",
       "      <th>instant_bookable_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.359</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.749</td>\n",
       "      <td>-1.433</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>-2.077</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.738</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.472</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>0.789</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.472</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-2.213</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.641</td>\n",
       "      <td>-1.450</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.525</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-1.296</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-1.493</td>\n",
       "      <td>0.743</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bathrooms  host_response_rate  number_of_reviews  \\\n",
       "0        -0.525     -0.435               0.295             -0.021   \n",
       "1         0.147     -0.435               0.295             -0.576   \n",
       "2        -1.472     -0.435               0.295             -0.576   \n",
       "3        -1.472     -0.435               0.295              0.067   \n",
       "4        -0.525     -0.435               0.295             -1.296   \n",
       "\n",
       "   review_scores_rating  bedrooms   beds  amenities_count  description_length  \\\n",
       "0                 0.359    -0.189 -0.687            0.583               0.749   \n",
       "1                -2.077    -0.189 -0.687            0.306               0.605   \n",
       "2                 0.789    -0.189 -0.687           -0.248              -0.937   \n",
       "3                -0.070    -2.213 -0.687            0.029               0.641   \n",
       "4                 0.216    -0.189 -0.687           -0.110              -1.493   \n",
       "\n",
       "   latitude         ...          cancellation_policy_super_strict_30  \\\n",
       "0    -1.433         ...                                            0   \n",
       "1     0.738         ...                                            0   \n",
       "2    -0.214         ...                                            0   \n",
       "3    -1.450         ...                                            0   \n",
       "4     0.743         ...                                            0   \n",
       "\n",
       "   cancellation_policy_super_strict_60  host_has_profile_pic_Blank  \\\n",
       "0                                    0                           0   \n",
       "1                                    0                           0   \n",
       "2                                    0                           0   \n",
       "3                                    0                           0   \n",
       "4                                    0                           0   \n",
       "\n",
       "   host_has_profile_pic_f  host_has_profile_pic_t  \\\n",
       "0                       0                       1   \n",
       "1                       0                       1   \n",
       "2                       0                       1   \n",
       "3                       0                       1   \n",
       "4                       0                       1   \n",
       "\n",
       "   host_identity_verified_Blank  host_identity_verified_f  \\\n",
       "0                             0                         1   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "\n",
       "   host_identity_verified_t  instant_bookable_f  instant_bookable_t  \n",
       "0                         0                   1                   0  \n",
       "1                         1                   1                   0  \n",
       "2                         1                   1                   0  \n",
       "3                         1                   1                   0  \n",
       "4                         1                   1                   0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(rootDirectory+\"/data/processed/X_test.csv\")\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pylab\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning: Regression using Neural Network\n",
    "### Training, validation and split\n",
    "In order to train our deep learning model and evaluate it, itâ€™s important to split the data into training, validation and testing datasets. We will train the model on a training set, and tune the model by validating the results on the validation dataset. Finally we will measure the ability of our model to generalize by testing our model on the testing dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(44466, 71) \n",
      "Validation set: \t(14823, 71) \n",
      "Test set: \t\t(14822, 71)\n"
     ]
    }
   ],
   "source": [
    "# Set feature and label variable\n",
    "features = X_train\n",
    "labels = y_train\n",
    "\n",
    "# Shuffle the train data order, and split by 60% train, 20% validation, 20% test data\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=104)\n",
    "\n",
    "X = np.zeros(shape=X_train.shape[0], dtype=int)\n",
    "y = np.zeros(shape=y_train.shape[0], dtype=int)\n",
    "\n",
    "splitter = sss.split(X, y)\n",
    "\n",
    "# Create randomize index\n",
    "train_index, validation_index = next(splitter)\n",
    "test_index = validation_index[:int(len(validation_index)/2)]\n",
    "validation_index = validation_index[int(len(validation_index)/2):]\n",
    "\n",
    "# Use iloc to look up dataframe index\n",
    "train_x, train_y = features.iloc[train_index], labels.iloc[train_index]\n",
    "test_x, test_y = features.iloc[test_index], labels.iloc[test_index]\n",
    "val_x, val_y = features.iloc[validation_index], labels.iloc[validation_index]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform into np.aarray for tensorflow\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "val_x = np.array(val_x)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Network:\n",
    "First Input layer: It is important for the first input layer to equal the number of property features.\n",
    "\n",
    "Hidden layer: The dense layers are used to prevent overfitting to the training set. The structure of the network was built through trial and error, and experiments. Note that the first iterations only had 2-3 layers. Additional layers were added at the end.\n",
    "\n",
    "Output layer: The linear activation function is used for regression problems with 1 output.\n",
    "Compile Model: Tested several optimization algorithms (â€˜sgdâ€™, â€˜RMSpropâ€™, and â€˜Adamâ€™) and selected based on results. Also tune the learning rate.\n",
    "\n",
    "Fit Model: Tune the number of epochs and batch size to match the computation capacity on my local computer. Training deep learning models are computationally expense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "input = train_x.shape[1]\n",
    "print(input)\n",
    "\n",
    "# create model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(512, input_dim=input, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(PReLU())\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.9))\n",
    "\n",
    "# model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(PReLU())\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.8))\n",
    "\n",
    "# model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "#     model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# define base model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(input, input_dim=input, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "def complex_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=input, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.9))\n",
    "\n",
    "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.8))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=10, batch_size=71, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29644/29644 [==============================] - 0s - loss: 2.5242     \n",
      "Epoch 2/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2300     \n",
      "Epoch 3/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2183     \n",
      "Epoch 4/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2134     \n",
      "Epoch 5/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2071     \n",
      "Epoch 6/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2012     \n",
      "Epoch 7/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1986     \n",
      "Epoch 8/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1961     \n",
      "Epoch 9/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1949     \n",
      "Epoch 10/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1936     \n",
      " 7739/14822 [==============>...............] - ETA: 0sEpoch 1/10\n",
      "29644/29644 [==============================] - 0s - loss: 2.4877     \n",
      "Epoch 2/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2380     \n",
      "Epoch 3/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2208     \n",
      "Epoch 4/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2157     \n",
      "Epoch 5/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2117     \n",
      "Epoch 6/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2076     \n",
      "Epoch 7/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2053     \n",
      "Epoch 8/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2027     \n",
      "Epoch 9/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2005     \n",
      "Epoch 10/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1984     \n",
      " 7881/14822 [==============>...............] - ETA: 0sEpoch 1/10\n",
      "29644/29644 [==============================] - 0s - loss: 2.6623     \n",
      "Epoch 2/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2330     \n",
      "Epoch 3/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2149     \n",
      "Epoch 4/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2110     \n",
      "Epoch 5/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2075     \n",
      "Epoch 6/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2050     \n",
      "Epoch 7/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.2010     \n",
      "Epoch 8/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1990     \n",
      "Epoch 9/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1971     \n",
      "Epoch 10/10\n",
      "29644/29644 [==============================] - 0s - loss: 0.1961     - ETA: 0s - loss\n",
      "13774/14822 [==========================>...] - ETA: 0sResults: 0.45 (0.01) MSE\n"
     ]
    }
   ],
   "source": [
    "#K Fold\n",
    "kfold = KFold(n_splits=3, random_state=seed)\n",
    "results = np.sqrt(cross_val_score(estimator, train_x, train_y, cv=kfold))\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29644/29644 [==============================] - 0s - loss: 3.8087     \n",
      "Epoch 2/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2985     \n",
      "Epoch 3/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2388     \n",
      "Epoch 4/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2215     \n",
      "Epoch 5/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2146     \n",
      "Epoch 6/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2097     \n",
      "Epoch 7/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2067     \n",
      "Epoch 8/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2048     \n",
      "Epoch 9/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2029     \n",
      "Epoch 10/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2018     \n",
      "Epoch 11/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2002     \n",
      "Epoch 12/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1990     \n",
      "Epoch 13/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1984     \n",
      "Epoch 14/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1983     \n",
      "Epoch 15/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1962     \n",
      "Epoch 16/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1953     \n",
      "Epoch 17/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1945     \n",
      "Epoch 18/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1953     \n",
      "Epoch 19/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1937     \n",
      "Epoch 20/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1939     \n",
      "Epoch 21/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1933     \n",
      "Epoch 22/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1920     \n",
      "Epoch 23/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1928     \n",
      "Epoch 24/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1916     \n",
      "Epoch 25/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1915     \n",
      "Epoch 26/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1912     \n",
      "Epoch 27/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1896     \n",
      "Epoch 28/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1905     \n",
      "Epoch 29/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1897     \n",
      "Epoch 30/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1896     \n",
      "Epoch 31/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1890     \n",
      "Epoch 32/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1891     \n",
      "Epoch 33/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1882     \n",
      "Epoch 34/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1879     \n",
      "Epoch 35/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1875     \n",
      "Epoch 36/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1876     \n",
      "Epoch 37/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1868     \n",
      "Epoch 38/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1869     \n",
      "Epoch 39/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1864     \n",
      "Epoch 40/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1862     \n",
      "Epoch 41/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1860     \n",
      "Epoch 42/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1855     \n",
      "Epoch 43/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1853     \n",
      "Epoch 44/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1851     \n",
      "Epoch 45/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1848     \n",
      "Epoch 46/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1839     \n",
      "Epoch 47/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1845     \n",
      "Epoch 48/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1835     \n",
      "Epoch 49/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1842     \n",
      "Epoch 50/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1834     \n",
      "14822/14822 [==============================] - 0s     \n",
      "Epoch 1/50\n",
      "29644/29644 [==============================] - 0s - loss: 4.1000     \n",
      "Epoch 2/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2785     \n",
      "Epoch 3/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2390     \n",
      "Epoch 4/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2249     \n",
      "Epoch 5/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2177     \n",
      "Epoch 6/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2142     \n",
      "Epoch 7/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2112     \n",
      "Epoch 8/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2094     \n",
      "Epoch 9/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2076     \n",
      "Epoch 10/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2061     \n",
      "Epoch 11/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2059     \n",
      "Epoch 12/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2031     \n",
      "Epoch 13/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2030     \n",
      "Epoch 14/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2017     \n",
      "Epoch 15/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2009     \n",
      "Epoch 16/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2007     \n",
      "Epoch 17/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2000     \n",
      "Epoch 18/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1994     \n",
      "Epoch 19/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1982     \n",
      "Epoch 20/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1985     \n",
      "Epoch 21/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1971     \n",
      "Epoch 22/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1967     \n",
      "Epoch 23/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1964     \n",
      "Epoch 24/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1953     \n",
      "Epoch 25/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1946     \n",
      "Epoch 26/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1946     \n",
      "Epoch 27/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1945     \n",
      "Epoch 28/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1941     \n",
      "Epoch 29/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1937     \n",
      "Epoch 30/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1931     \n",
      "Epoch 31/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1927     \n",
      "Epoch 32/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1921     \n",
      "Epoch 33/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1914     \n",
      "Epoch 34/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1918     \n",
      "Epoch 35/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1926     \n",
      "Epoch 36/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1909     \n",
      "Epoch 37/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1909     \n",
      "Epoch 38/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1904     \n",
      "Epoch 39/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1899     \n",
      "Epoch 40/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1901     \n",
      "Epoch 41/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1897     \n",
      "Epoch 42/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1892     \n",
      "Epoch 43/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1890     \n",
      "Epoch 44/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1890     \n",
      "Epoch 45/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1886     \n",
      "Epoch 46/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1885     \n",
      "Epoch 47/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1884     \n",
      "Epoch 48/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1878     \n",
      "Epoch 49/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1879     \n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29644/29644 [==============================] - 0s - loss: 0.1873     \n",
      "14822/14822 [==============================] - 0s     \n",
      "Epoch 1/50\n",
      "29644/29644 [==============================] - 0s - loss: 3.9394     \n",
      "Epoch 2/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2792     \n",
      "Epoch 3/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2356     \n",
      "Epoch 4/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2218     \n",
      "Epoch 5/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2139     \n",
      "Epoch 6/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2100     \n",
      "Epoch 7/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2077     \n",
      "Epoch 8/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2056     \n",
      "Epoch 9/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2036     \n",
      "Epoch 10/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2030     \n",
      "Epoch 11/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.2001     \n",
      "Epoch 12/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1995     \n",
      "Epoch 13/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1985     \n",
      "Epoch 14/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1978     \n",
      "Epoch 15/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1955     \n",
      "Epoch 16/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1955     \n",
      "Epoch 17/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1946     \n",
      "Epoch 18/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1939     \n",
      "Epoch 19/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1932     \n",
      "Epoch 20/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1931     \n",
      "Epoch 21/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1921     \n",
      "Epoch 22/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1918     \n",
      "Epoch 23/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1915     \n",
      "Epoch 24/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1911     \n",
      "Epoch 25/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1905     \n",
      "Epoch 26/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1904     \n",
      "Epoch 27/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1894     \n",
      "Epoch 28/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1906     \n",
      "Epoch 29/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1889     \n",
      "Epoch 30/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1883     \n",
      "Epoch 31/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1880     \n",
      "Epoch 32/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1872     \n",
      "Epoch 33/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1879     \n",
      "Epoch 34/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1865     \n",
      "Epoch 35/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1876     \n",
      "Epoch 36/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1864     \n",
      "Epoch 37/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1864     \n",
      "Epoch 38/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1871     \n",
      "Epoch 39/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1863     \n",
      "Epoch 40/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1854     \n",
      "Epoch 41/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1851     \n",
      "Epoch 42/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1851     \n",
      "Epoch 43/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1847     \n",
      "Epoch 44/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1838     \n",
      "Epoch 45/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1855     \n",
      "Epoch 46/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1838     \n",
      "Epoch 47/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1843     \n",
      "Epoch 48/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1830     \n",
      "Epoch 49/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1839     \n",
      "Epoch 50/50\n",
      "29644/29644 [==============================] - 0s - loss: 0.1844     \n",
      " 7171/14822 [=============>................] - ETA: 0s Standardized: 0.21 (0.01) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=71, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=3, random_state=seed)\n",
    "results = np.sqrt(cross_val_score(pipeline, train_x, train_y, cv=kfold))\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "49407/49407 [==============================] - 3s - loss: 21.1156     \n",
      "Epoch 2/100\n",
      "49407/49407 [==============================] - 3s - loss: 11.1337     \n",
      "Epoch 3/100\n",
      "49407/49407 [==============================] - 3s - loss: 5.6530     \n",
      "Epoch 4/100\n",
      "49407/49407 [==============================] - 3s - loss: 3.9511     \n",
      "Epoch 5/100\n",
      "49407/49407 [==============================] - 3s - loss: 3.1819     \n",
      "Epoch 6/100\n",
      "49407/49407 [==============================] - 3s - loss: 2.5780     \n",
      "Epoch 7/100\n",
      "29184/49407 [================>.............] - ETA: 1s - loss: 2.2503"
     ]
    }
   ],
   "source": [
    "# Evaluate complex model\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "final_estimators = []\n",
    "final_estimators.append(('standardize', StandardScaler()))\n",
    "final_estimators.append(('mlp', KerasRegressor(build_fn=complex_model, epochs=100, batch_size=512, verbose=1)))\n",
    "pipeline = Pipeline(final_estimators)\n",
    "kfold = KFold(n_splits=3, random_state=seed)\n",
    "results = np.sqrt(cross_val_score(pipeline, X_train, y_train, cv=kfold))\n",
    "print(\"Wider: %.2f (%.2f) RMSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "estimator.fit(X, y)\n",
    "prediction = estimator.predict(X)\n",
    "accuracy_score(y, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Several Optimizer (sgd, rmsp, adam):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#SGD: Tune learning rate \n",
    "# optimizers.SGD(lr=0.01, momentum=0.005, decay=0.0, nesterov=False)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### specify the number of epochs and save best validation result\n",
    "\n",
    "epochs = 100\n",
    "checkpointer = ModelCheckpoint(filepath= rootDirectory + '/models/weights.best.from_scratch_stdscaler_sgd.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "#train data\n",
    "sgd_history = model.fit(train_x, train_y, epochs=epochs, batch_size=512, callbacks=[checkpointer], verbose=1, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "# list all data in history\n",
    "print(sgd_history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "plt.plot(sgd_history.history['loss'])\n",
    "plt.plot(sgd_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ADAM\n",
    "# optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### specify the number of epochs and save best validation result\n",
    "\n",
    "epochs = 100\n",
    "checkpointer = ModelCheckpoint(filepath= rootDirectory + '/models/weights.best.from_scratch_stdscaler_adam.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "#train data\n",
    "adam_history = model.fit(train_x, train_y, epochs=epochs, batch_size=512, callbacks=[checkpointer], verbose=1, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "# list all data in history\n",
    "print(adam_history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "plt.plot(adam_history.history['loss'])\n",
    "plt.plot(adam_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMSPROP\n",
    "# optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### specify the number of epochs and save best validation result\n",
    "\n",
    "epochs = 100\n",
    "checkpointer = ModelCheckpoint(filepath= rootDirectory + '/models/weights.best.from_scratch_stdscaler_RMSprop.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "#train data\n",
    "RMSprop_history = model.fit(train_x, train_y, epochs=epochs, batch_size=512, callbacks=[checkpointer], verbose=1, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "# list all data in history\n",
    "print(RMSprop_history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "plt.plot(RMSprop_history.history['loss'])\n",
    "plt.plot(RMSprop_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Weights and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load weights with best results: RMSprop\n",
    "# model.load_weights(rootDirectory + '/models/weights.best.from_scratch_minmax_RMSprop.hdf5')\n",
    "\n",
    "# model.load_weights(rootDirectory + '/models/weights.best.from_scratch_minmax_adam.hdf5')\n",
    "\n",
    "# model.load_weights(rootDirectory + '/models/weights.best.from_scratch_minmax_sgd.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "model.load_weights(rootDirectory + '/models/weights.best.from_scratch_stdscaler_RMSprop.hdf5')\n",
    "pred = model.predict(test_x)\n",
    "score = mean_squared_error(test_y, pred)\n",
    "print(\"Results: {} STD RMSP MSE\".format(score))\n",
    "\n",
    "model.load_weights(rootDirectory + '/models/weights.best.from_scratch_stdscaler_adam.hdf5')\n",
    "pred = model.predict(test_x)\n",
    "score = mean_squared_error(test_y, pred)\n",
    "print(\"Results: {} STD ADAM MSE\".format(score))\n",
    "\n",
    "model.load_weights(rootDirectory + '/models/weights.best.from_scratch_stdscaler_sgd.hdf5')\n",
    "pred = model.predict(test_x)\n",
    "score = mean_squared_error(test_y, pred)\n",
    "print(\"Results: {} STD SGD MSE\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load Final selected weight\n",
    "model.load_weights(rootDirectory + '/models/weights.best.from_scratch_stdscaler_RMSprop.hdf5')\n",
    "\n",
    "# perform prediction on 20% unseen testing data\n",
    "pred = model.predict(test_x)\n",
    "score = mean_squared_error(test_y, pred)\n",
    "print(\"Results: {} MSE\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning\n",
    "dl_test = np.array(X_test)\n",
    "dl_y_pred = model.predict(dl_test)\n",
    "\n",
    "# View shape\n",
    "display(dl_y_pred.shape)\n",
    "print (\"DL Prediction Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Output Table: Baseline using Linear Regression\n",
    "Compile results for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original test data to pull Id List\n",
    "test_detail = pd.read_csv(rootDirectory+\"/data/raw/test.csv\")\n",
    "test_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Transform to List\n",
    "dl_pred = []\n",
    "\n",
    "for item in dl_y_pred:\n",
    "    dl_pred.append(str(round(item[0],4)))\n",
    "\n",
    "# Output table\n",
    "output = pd.DataFrame({'id': test_detail['id'],\n",
    "        'log_price': dl_pred}).set_index('id')\n",
    "\n",
    "display(output.shape)\n",
    "display(output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export CSV\n",
    "# from datetime import datetime\n",
    "# output.to_csv(rootDirectory+'/models/submission/sub_DL_STD_RMSP_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Keras Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Use scikit-learn to grid search the batch size and epochs\n",
    "# import numpy\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# def create_model():\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(512, input_dim=input, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.9))\n",
    "#     model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.8))\n",
    "#     model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='mean_squared_error', optimizer='rmsprop') \n",
    "#     return model\n",
    "\n",
    "# # fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# numpy.random.seed(seed)\n",
    "\n",
    "# # split into input (X) and output (Y) variables\n",
    "# # X = train_x\n",
    "# # Y = train_y\n",
    "\n",
    "# X = X_train\n",
    "# Y = y_train\n",
    "\n",
    "# # create model\n",
    "# model = KerasRegressor(build_fn=create_model, verbose=1)\n",
    "# # define the grid search parameters\n",
    "# # batch_size = [256, 512, 768]\n",
    "# # epochs = [10, 50, 100]\n",
    "\n",
    "# batch_size = [512]\n",
    "# epochs = [10]\n",
    "\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = grid.fit(X, Y)\n",
    "\n",
    "# # summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # MLP with 10-fold cross validation\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# import numpy\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "# # fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# numpy.random.seed(seed)\n",
    "# # split into input (X) and output (Y) variables\n",
    "# # X = X_train\n",
    "# # Y = y_train\n",
    "\n",
    "# X = train_x\n",
    "# Y = train_y\n",
    "\n",
    "# # define 10-fold cross validation test harness\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# cvscores = []\n",
    "# for train, test in kfold.split(X, Y):\n",
    "#   # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(512, input_dim= train_x_kfold.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.9))\n",
    "#     model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "#     model.add(PReLU())\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.8))\n",
    "#     model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "#     # Fit the model\n",
    "#     model.fit(X[train], Y[train], epochs=10, batch_size=512, verbose=0)\n",
    "#     # evaluate the model\n",
    "#     scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "#     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#     cvscores.append(scores[1] * 100)\n",
    "# print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
